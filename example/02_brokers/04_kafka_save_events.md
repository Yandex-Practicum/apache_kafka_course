# Как сохранять различные события в Kafka

Первое, с чем нужно определиться, — как именно вы будете сохранять события в Kafka. Есть три возможные стратегии:

1. **Единый топик для всех событий**. Все события, независимо от типа сущности или агрегата, сохраняются в один общий топик.
2. **Топик для каждого типа сущности**. Создаются отдельные топики для событий, относящихся к определённым типам сущностей или агрегатов. Например, можно иметь отдельный топик для всех событий, которые относятся к пользователям, и отдельный топик для событий, относящихся к фильмам.
3. **Топик для каждого экземпляра сущности**. Стратегия предполагает создание отдельных топиков для каждого экземпляра сущности. Это может быть полезно в сценариях, где требуется изолировать обработку данных для конкретных инстанций.

Третья стратегия применима только для сущностей или агрегатов с низкой {{кардинальностью}}[p2f_cardinality]. Если для каждого экземляра сущности будет создаваться отдельный топик, то скоро в системе будет бесконечное количество топиков. Работать с этим будет невозможно: если вы захотите выполнить какие-либо агрегации, например узнать, какой фильм картотеки пользуется наибольшей популярностью, вам придётся считать большое количество топиков. 

Kafka сама по себе очень ограничено применима к аналитике; если нужно иметь много срезов данных, то лучше для этого использовать специализированные колоночные БД. Кроме того, бесконтрольный рост топиков в итоге «убьёт» Kafka. Дело в том, что каждый топик на каждую партицию удерживает файловый дескриптор и активно взаимодействует с ним. На сервере попросту могут закончиться файловые дескрипторы.

Первая и вторая стратегии имеют свои плюсы и минусы. С единым топиком просто осуществить глобальный обзор всех событий. С другой стороны, имея отдельный топик под каждый тип сущности, вы можете партиционировать и масштабировать конкретный поток событий, если это будет необходимо. Выбор зависит от конкретного кейса использования. При этом никто не запрещает по необходимости «сливать» топики друг с другом. Например, имея топики `users` и `comments`, можно реализовать слияния данных в новый топик `users_with_comments`, в котором будут содержаться комментарии с их автором.

На данный момент ваша задача — отслеживать пользовательские события на сайте. Это могут быть клики, просмотры страниц, лайки. В будущем также может возникнуть потребность отслеживать и другие активности в онлайн-кинотеатре. Например, может быть полезно узнать, сколько вендоры добавляют новых фильмов каждый месяц. Поэтому создание разделённых топиков для различных типов сущностей выглядит разумным решением, ориентированным на будущее.

Топик нужно разделить на партиции. Для ключа партиционирования есть три кандидата:

- **Партиционирование по типу события**. Если вам важно собирать и обрабатывать все события определённого типа вместе, то вы можете использовать тип события в качестве ключа для партиционирования. Это упрощает агрегацию данных по типу события и позволяет быстро обрабатывать все события одного типа.

- **Партиционирование по пользователям** (ключ `user_id`). Если вам важно отслеживать все события для конкретного пользователя, то можно использовать `user_id` в качестве ключа партиционирования. Это обеспечивает быструю обработку всех событий для конкретного пользователя и упрощает агрегацию данных на уровне пользователя.

- **Партиционирование по сессии пользователя** (ключ `session_id`). Если вам важно отслеживать все события в рамках одной сессии пользователя, то можно использовать `session_id` в качестве ключа партиционирования. Это позволяет быстро обрабатывать все события в рамках одной сессии и упрощает анализ действий пользователя в рамках одной сессии.

Момент про трудности перевода. В английском языке для обозначения операции считывания в основном используется слово consume. Буквально оно означает «потреблять» или «расходовать». Если на русском выражения плана «читать из Кафки» режут слух, то можно пользоваться одним из жаргонизмов, гуляющих в профессиональной среде, — «доить Кафку».

Kafka оптимизирована под высокую нагрузку. Пока сервис онлайн-кинотеатра не достиг международной популярности, клиенты — браузер пользователя или мобильное приложение — могут отправлять события о прогрессе просмотра практически напрямую для записи в топик. Вам потребуется лишь небольшая прослойка кода в виде API, которая под капотом будет без каких-либо преобразований отправлять событие в Kafka.

Развитием этой идеи может стать некоторая буферизация событий в сервисе-прослойке. После того как количество пользователей (а следовательно, и просмотров) достигнет порогового значения, сервис может начать накапливать события от клиентов, которые, например, поступают каждую секунду, а производить запись в топик раз в минуту. Это значительно снизит нагрузку на Kafka, но потребует осторожной реализации. А именно: придётся подумать над тем, как буферы в разных инстансах сервиса-прослойки будут синхронизироваться между собой и что произойдёт, если один из инстансов выйдет из строя. 

Также может понадобиться реализация политики [sticky session](https://habr.com/ru/post/231523/){target="_blank"} — метода балансировки нагрузки, при котором запросы клиента передаются на один и тот же сервер группы. Обсуждение этих решений выходит за рамки курса.
